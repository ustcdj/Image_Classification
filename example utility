# Dependencies
import argparse
import numpy as np
import torch
import matplotlib.pyplot as plt
from torchvision import datasets, transforms, models
from torch import nn, optim
import torch.nn.functional as F
from collections import OrderedDict
import time
from PIL import Image
import matplotlib

from workspace_utils import active_session

# Load and transform data from data_dir
def preproc(data_dir):

    # Data directories
    train_dir = data_dir + '/train'
    valid_dir = data_dir + '/valid'
    test_dir = data_dir + '/test'

    # Define your transforms for the training, validation, and testing sets
    train_transforms = transforms.Compose([transforms.RandomRotation(30),
                                        transforms.RandomResizedCrop(224),
                                        transforms.RandomHorizontalFlip(),
                                        transforms.ToTensor(),
                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
    valid_transforms = transforms.Compose([transforms.Resize(256),
                                        transforms.CenterCrop(224),
                                        transforms.ToTensor(),
                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
    test_transforms = transforms.Compose([transforms.Resize(256),
                                        transforms.CenterCrop(224),
                                        transforms.ToTensor(),
                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

    # Load the datasets with ImageFolder
    image_datasets = {}
    image_datasets["train"] = datasets.ImageFolder(train_dir, transform=train_transforms)
    image_datasets["valid"] = datasets.ImageFolder(valid_dir, transform=valid_transforms)
    image_datasets["test"] = datasets.ImageFolder(test_dir, transform=test_transforms)

    # Using the image datasets and the trainforms, define the dataloaders
    train_loader = torch.utils.data.DataLoader(image_datasets["train"], batch_size=64, shuffle=True)
    valid_loader = torch.utils.data.DataLoader(image_datasets["valid"], batch_size=32)
    test_loader = torch.utils.data.DataLoader(image_datasets["test"], batch_size=32)

    print(f"Data loaded from {data_dir} directory.")

    return image_datasets, train_loader, valid_loader, test_loader

    def build_model(arch, hidden_units):

        # Load in a pre-trained model, DenseNet default
        if arch.lower() == "vgg13":
            model = models.vgg13(pretrained=True)
        else:
            model = models.densenet121(pretrained=True)

        # Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout
        for param in model.parameters():
            param.requires_grad = False # Freeze parameters so we don't backprop through them

        if arch.lower() == "vgg13":
            classifier = nn.Sequential(OrderedDict([
                                ('dropout1', nn.Dropout(0.1)),
                                ('fc1', nn.Linear(25088, hidden_units)), # 25088 must match
                                ('relu1', nn.ReLU()),
                                ('dropout2', nn.Dropout(0.1)),
                                ('fc2', nn.Linear(hidden_units, 102)),
                                ('output', nn.LogSoftmax(dim=1))
                                ]))
        else:
            classifier = nn.Sequential(OrderedDict([
                                ('dropout1', nn.Dropout(0.1)),
                                ('fc1', nn.Linear(1024, hidden_units)), # 1024 must match
                                ('relu1', nn.ReLU()),
                                ('dropout2', nn.Dropout(0.1)),
                                ('fc2', nn.Linear(hidden_units, 102)),
                                ('output', nn.LogSoftmax(dim=1))
                                ]))

        model.classifier = classifier
        print(f"Model built from {arch} and {hidden_units} hidden units.")

        return model


    # Measure the validation loss and accuracy
    def validation(model, dataloader, criterion, device):
        loss = 0
        accuracy = 0
        with torch.no_grad():
            for images, labels in iter(dataloader):

                images, labels = images.to(device), labels.to(device) # Move input and label tensors to the GPU

                output = model.forward(images)
                loss += criterion(output, labels).item()

                ps = torch.exp(output) # get the class probabilities from log-softmax
                equality = (labels.data == ps.max(dim=1)[1])
                accuracy += equality.type(torch.FloatTensor).mean()

        return loss, accuracy


    # Train model
    def train_model(model, train_loader, valid_loader, learning_rate, epochs, gpu):

        # Criterion and optimizer
        criterion = nn.NLLLoss()
        optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)

        # Train the classifier layers using backpropagation using the pre-trained network to get the features
        device = torch.device("cuda:0" if gpu else "cpu")
        print(type(model))
        model.to(device)
        print_every = 40
        steps = 0
        running_loss = 0
        train_accuracy = 0

        print(f'Training with {learning_rate} learning rate, {epochs} epochs, and {(gpu)*"cuda" + (not gpu)*"cpu"} computing.')

        with active_session():
            for e in range(epochs):

                model.train() # Dropout is turned on for training

                for images, labels in iter(train_loader):

                    images, labels = images.to(device), labels.to(device) # Move input and label tensors to the GPU

                    steps += 1
                    optimizer.zero_grad()
                    output = model.forward(images)
                    loss = criterion(output, labels)
                    loss.backward()
                    optimizer.step()
                    running_loss += loss.item()

                    # get the class probabilities from log-softmax
                    ps = torch.exp(output)
                    equality = (labels.data == ps.max(dim=1)[1])
                    train_accuracy += equality.type(torch.FloatTensor).mean()

                    if steps % print_every == 0:

                        model.eval() # Make sure network is in eval mode for inference

                        with torch.no_grad():
                            valid_loss, valid_accuracy = validation(model, valid_loader, criterion, device)

                        print("Epoch: {}/{}.. ".format(e+1, epochs),
                            "Training Loss: {:.3f}.. ".format(running_loss/print_every),
                            "Training Accuracy: {:.3f}".format(train_accuracy/print_every),
                            "Validation Loss: {:.3f}.. ".format(valid_loss/len(valid_loader)),
                            "Validation Accuracy: {:.3f}".format(valid_accuracy/len(valid_loader)))

                        running_loss = 0
                        train_accuracy = 0
                        model.train() # Make sure training is back on

            print("\nTraining completed!")

        return model, optimizer, criterion

        def process_image(image_path):
            ''' Scales, crops, and normalizes a PIL image for a PyTorch model,
                returns an Numpy array
            '''

            pil_image = Image.open(image_path)

            # Process a PIL image for use in a PyTorch model
            # Resize the images where the shortest side is 256 pixels, keeping the aspect ratio
            width, height = pil_image.size
            aspect_ratio = width / height
            if aspect_ratio > 1:
                pil_image = pil_image.resize((round(aspect_ratio * 256), 256))
            else:
                pil_image = pil_image.resize((256, round(256 / aspect_ratio)))

            # Crop out the center 224x224 portion of the image
            width, height = pil_image.size
            new_width = 224
            new_height = 224
            left = (width - new_width)/2
            top = (height - new_height)/2
            right = (width + new_width)/2
            bottom = (height + new_height)/2
            pil_image = pil_image.crop((round(left), round(top), round(right), round(bottom)))

            # Convert color channels to 0-1
            np_image = np.array(pil_image) / 255

            # Normalize the image
            np_image = (np_image - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])

            # Reorder dimensions
            np_image = np_image.transpose((2, 0, 1))

            return np_image


        # Display the original image (cropped)
        def imshow(image, ax=None, title=None):
            if ax is None:
                fig, ax = plt.subplots()

            # PyTorch tensors assume the color channel is the first dimension
            # but matplotlib assumes is the third dimension
            image = image.transpose((1, 2, 0))

            # Undo preprocessing
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            image = std * image + mean

            # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
            image = np.clip(image, 0, 1)

            ax.imshow(image)

            return ax

            def predict(np_image, model, topk, gpu):
                ''' Predict the class (or classes) of an image using a trained deep learning model.
                '''

                # Implement the code to predict the class from an image file
                device = torch.device("cuda:0" if gpu else "cpu")

                model.to(device)
                model.eval()

                with torch.no_grad():
                    images = torch.from_numpy(np_image)
                    images = images.unsqueeze(0)
                    images = images.type(torch.FloatTensor)
                    images = images.to(device) # Move input tensors to the GPU/CPU

                    output = model.forward(images)
                    ps = torch.exp(output) # get the class probabilities from log-softmax

                    probs, indices = torch.topk(ps, topk)
                    probs = [float(prob) for prob in probs[0]]
                    inv_map = {v: k for k, v in model.class_to_idx.items()}
                    classes = [inv_map[int(index)] for index in indices[0]]

                return probs, classes
